{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-ESRGAN (PyTorch)\n",
    "\n",
    "This is the inference code for [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) extracted from the [ai-forever](https://github.com/ai-forever/Real-ESRGAN) PyTorch implementation. I've removed redundant code, introduced Einops, and incorporated the Hugging Face client to download and cache the weights from the hub.\n",
    "\n",
    "Real-ESRGAN is an enhanced version of [ESRGAN](https://github.com/xinntao/ESRGAN) that uses a more \"real-world\" degradation process to generate the synthetic training images. In super-resolution, artifacts in the original image can be amplified by the upscaling process. Real-ESRGAN aims to also remove these artifacts so the final image looks like it was natively high-resolution.\n",
    "\n",
    "The original and all derived works are [BSD-3](https://github.com/xinntao/Real-ESRGAN/blob/master/LICENSE) licensed.\n",
    "\n",
    "TODO: Replace `load_weights` with `from_pretrained`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import init as init\n",
    "from torch.nn.modules.batchnorm import _BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/ai-forever/Real-ESRGAN\n",
    "HF_MODELS = {\n",
    "    2: dict(\n",
    "        repo_id=\"ai-forever/Real-ESRGAN\",\n",
    "        filename=\"RealESRGAN_x2.pth\",\n",
    "        model=None,\n",
    "    ),\n",
    "    4: dict(\n",
    "        repo_id=\"ai-forever/Real-ESRGAN\",\n",
    "        filename=\"RealESRGAN_x4.pth\",\n",
    "        model=None,\n",
    "    ),\n",
    "    8: dict(\n",
    "        repo_id=\"ai-forever/Real-ESRGAN\",\n",
    "        filename=\"RealESRGAN_x8.pth\",\n",
    "        model=None,\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def pad_reflect(image, pad_size):\n",
    "    imsize = image.shape\n",
    "    height, width = imsize[:2]\n",
    "    new_img = np.zeros([height + pad_size * 2, width + pad_size * 2, imsize[2]]).astype(np.uint8)\n",
    "    new_img[pad_size:-pad_size, pad_size:-pad_size, :] = image\n",
    "    new_img[0:pad_size, pad_size:-pad_size, :] = np.flip(image[0:pad_size, :, :], axis=0)  # top\n",
    "    new_img[-pad_size:, pad_size:-pad_size, :] = np.flip(image[-pad_size:, :, :], axis=0)  # bottom\n",
    "    new_img[:, 0:pad_size, :] = np.flip(new_img[:, pad_size : pad_size * 2, :], axis=1)  # # left\n",
    "    new_img[:, -pad_size:, :] = np.flip(new_img[:, -pad_size * 2 : -pad_size, :], axis=1)  # right\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def unpad_image(image, pad_size):\n",
    "    return image[pad_size:-pad_size, pad_size:-pad_size, :]\n",
    "\n",
    "\n",
    "def pad_patch(image_patch, padding_size, channel_last=True):\n",
    "    if channel_last:\n",
    "        return np.pad(\n",
    "            image_patch,\n",
    "            ((padding_size, padding_size), (padding_size, padding_size), (0, 0)),\n",
    "            \"edge\",\n",
    "        )\n",
    "    else:\n",
    "        return np.pad(\n",
    "            image_patch,\n",
    "            ((0, 0), (padding_size, padding_size), (padding_size, padding_size)),\n",
    "            \"edge\",\n",
    "        )\n",
    "\n",
    "\n",
    "def unpad_patches(image_patches, padding_size):\n",
    "    return image_patches[:, padding_size:-padding_size, padding_size:-padding_size, :]\n",
    "\n",
    "\n",
    "def split_image_into_overlapping_patches(image_array, patch_size, padding_size=2):\n",
    "    xmax, ymax, _ = image_array.shape\n",
    "    x_remainder = xmax % patch_size\n",
    "    y_remainder = ymax % patch_size\n",
    "\n",
    "    # modulo here is to avoid extending of patch_size instead of 0\n",
    "    x_extend = (patch_size - x_remainder) % patch_size\n",
    "    y_extend = (patch_size - y_remainder) % patch_size\n",
    "\n",
    "    # make sure the image is divisible into regular patches\n",
    "    extended_image = np.pad(image_array, ((0, x_extend), (0, y_extend), (0, 0)), \"edge\")\n",
    "\n",
    "    # add padding around the image to simplify computations\n",
    "    padded_image = pad_patch(extended_image, padding_size, channel_last=True)\n",
    "\n",
    "    patches = []\n",
    "    xmax, ymax, _ = padded_image.shape\n",
    "    x_lefts = range(padding_size, xmax - padding_size, patch_size)\n",
    "    y_tops = range(padding_size, ymax - padding_size, patch_size)\n",
    "\n",
    "    for x in x_lefts:\n",
    "        for y in y_tops:\n",
    "            x_left = x - padding_size\n",
    "            y_top = y - padding_size\n",
    "            x_right = x + patch_size + padding_size\n",
    "            y_bottom = y + patch_size + padding_size\n",
    "            patch = padded_image[x_left:x_right, y_top:y_bottom, :]\n",
    "            patches.append(patch)\n",
    "    return np.array(patches), padded_image.shape\n",
    "\n",
    "\n",
    "def stitch_together(patches, padded_image_shape, target_shape, padding_size=4):\n",
    "    xmax, ymax, _ = padded_image_shape\n",
    "    patches = unpad_patches(patches, padding_size)\n",
    "    patch_size = patches.shape[1]\n",
    "    n_patches_per_row = ymax // patch_size\n",
    "    complete_image = np.zeros((xmax, ymax, 3))\n",
    "\n",
    "    row = -1\n",
    "    col = 0\n",
    "    for i in range(len(patches)):\n",
    "        if i % n_patches_per_row == 0:\n",
    "            row += 1\n",
    "            col = 0\n",
    "        complete_image[\n",
    "            row * patch_size : (row + 1) * patch_size, col * patch_size : (col + 1) * patch_size, :\n",
    "        ] = patches[i]\n",
    "        col += 1\n",
    "    return complete_image[0 : target_shape[0], 0 : target_shape[1], :]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def default_init_weights(module_list, scale=1, bias_fill=0, **kwargs):\n",
    "    if not isinstance(module_list, list):\n",
    "        module_list = [module_list]\n",
    "    for module in module_list:\n",
    "        for m in module.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, **kwargs)\n",
    "                m.weight.data *= scale\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal_(m.weight, **kwargs)\n",
    "                m.weight.data *= scale\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "            elif isinstance(m, _BatchNorm):\n",
    "                init.constant_(m.weight, 1)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "\n",
    "\n",
    "def make_layer(basic_block, num_basic_block, **kwarg):\n",
    "    layers = []\n",
    "    for _ in range(num_basic_block):\n",
    "        layers.append(basic_block(**kwarg))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def pixel_unshuffle(x, scale):\n",
    "    _, _, h, w = x.shape\n",
    "    assert h % scale == 0 and w % scale == 0, \"Height and width must be divisible by scale\"\n",
    "    return einops.rearrange(\n",
    "        x,\n",
    "        \"b c (h s1) (w s2) -> b (c s1 s2) h w\",\n",
    "        s1=scale,\n",
    "        s2=scale,\n",
    "    )\n",
    "\n",
    "\n",
    "class ResidualDenseBlock(nn.Module):\n",
    "    def __init__(self, num_feat=64, num_grow_ch=32):\n",
    "        super(ResidualDenseBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_feat, num_grow_ch, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(num_feat + num_grow_ch, num_grow_ch, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(num_feat + 2 * num_grow_ch, num_grow_ch, 3, 1, 1)\n",
    "        self.conv4 = nn.Conv2d(num_feat + 3 * num_grow_ch, num_grow_ch, 3, 1, 1)\n",
    "        self.conv5 = nn.Conv2d(num_feat + 4 * num_grow_ch, num_feat, 3, 1, 1)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        default_init_weights([self.conv1, self.conv2, self.conv3, self.conv4, self.conv5], 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.lrelu(self.conv1(x))\n",
    "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
    "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
    "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
    "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
    "        return x5 * 0.2 + x  # scale the residual by a factor of 0.2\n",
    "\n",
    "\n",
    "class RRDB(nn.Module):\n",
    "    def __init__(self, num_feat, num_grow_ch=32):\n",
    "        super(RRDB, self).__init__()\n",
    "        self.rdb1 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
    "        self.rdb2 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
    "        self.rdb3 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.rdb1(x)\n",
    "        out = self.rdb2(out)\n",
    "        out = self.rdb3(out)\n",
    "        return out * 0.2 + x  # scale the residual by a factor of 0.2\n",
    "\n",
    "\n",
    "class RRDBNet(nn.Module):\n",
    "    def __init__(self, num_in_ch, num_out_ch, scale=4, num_feat=64, num_block=23, num_grow_ch=32):\n",
    "        super(RRDBNet, self).__init__()\n",
    "        self.scale = scale\n",
    "        if scale == 2:\n",
    "            num_in_ch = num_in_ch * 4\n",
    "        elif scale == 1:\n",
    "            num_in_ch = num_in_ch * 16\n",
    "        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)\n",
    "        self.body = make_layer(RRDB, num_block, num_feat=num_feat, num_grow_ch=num_grow_ch)\n",
    "        self.conv_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
    "        self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
    "        self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
    "        if scale == 8:\n",
    "            self.conv_up3 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
    "        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
    "        self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.scale == 2:\n",
    "            feat = pixel_unshuffle(x, scale=2)\n",
    "        elif self.scale == 1:\n",
    "            feat = pixel_unshuffle(x, scale=4)\n",
    "        else:\n",
    "            feat = x\n",
    "        feat = self.conv_first(feat)\n",
    "        body_feat = self.conv_body(self.body(feat))\n",
    "        feat = feat + body_feat\n",
    "        # upsample\n",
    "        feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode=\"nearest\")))\n",
    "        feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode=\"nearest\")))\n",
    "        if self.scale == 8:\n",
    "            feat = self.lrelu(self.conv_up3(F.interpolate(feat, scale_factor=2, mode=\"nearest\")))\n",
    "        out = self.conv_last(self.lrelu(self.conv_hr(feat)))\n",
    "        return out\n",
    "\n",
    "\n",
    "class RealESRGAN:\n",
    "    def __init__(self, scale=4, device=None):\n",
    "        self.device = device\n",
    "        self.scale = scale\n",
    "        self.model = RRDBNet(\n",
    "            num_in_ch=3,\n",
    "            num_out_ch=3,\n",
    "            num_feat=64,\n",
    "            num_block=23,\n",
    "            num_grow_ch=32,\n",
    "            scale=scale,\n",
    "        )\n",
    "\n",
    "    def load_weights(self):\n",
    "        assert self.scale in [2, 4, 8], \"You can download models only with scales: 2, 4, 8\"\n",
    "        config = HF_MODELS[self.scale]\n",
    "        cache_path = hf_hub_download(config[\"repo_id\"], filename=config[\"filename\"])\n",
    "        loadnet = torch.load(cache_path)\n",
    "        if \"params\" in loadnet:\n",
    "            self.model.load_state_dict(loadnet[\"params\"], strict=True)\n",
    "        elif \"params_ema\" in loadnet:\n",
    "            self.model.load_state_dict(loadnet[\"params_ema\"], strict=True)\n",
    "        else:\n",
    "            self.model.load_state_dict(loadnet, strict=True)\n",
    "        self.model.eval().to(device=self.device)\n",
    "\n",
    "    @torch.autocast(\"cuda\")\n",
    "    def predict(self, lr_image, batch_size=4, patches_size=192, padding=24, pad_size=15):\n",
    "        if not isinstance(lr_image, np.ndarray):\n",
    "            lr_image = np.array(lr_image)\n",
    "        if lr_image.min() < 0.0:\n",
    "            lr_image = (lr_image + 1.0) / 2.0\n",
    "        if lr_image.max() <= 1.0:\n",
    "            lr_image = lr_image * 255.0\n",
    "        lr_image = pad_reflect(lr_image, pad_size)\n",
    "        patches, p_shape = split_image_into_overlapping_patches(\n",
    "            lr_image,\n",
    "            patch_size=patches_size,\n",
    "            padding_size=padding,\n",
    "        )\n",
    "        patches = torch.Tensor(patches / 255.0)\n",
    "        image = einops.rearrange(patches, \"b h w c -> b c h w\").to(device=self.device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            res = self.model(image[0:batch_size])\n",
    "            for i in range(batch_size, image.shape[0], batch_size):\n",
    "                res = torch.cat((res, self.model(image[i : i + batch_size])), 0)\n",
    "\n",
    "        scale = self.scale\n",
    "        sr_image = einops.rearrange(res.clamp(0, 1), \"b c h w -> b h w c\").cpu().numpy()\n",
    "        padded_size_scaled = tuple(np.multiply(p_shape[0:2], scale)) + (3,)\n",
    "        scaled_image_shape = tuple(np.multiply(lr_image.shape[0:2], scale)) + (3,)\n",
    "        sr_image = stitch_together(\n",
    "            sr_image,\n",
    "            padded_image_shape=padded_size_scaled,\n",
    "            target_shape=scaled_image_shape,\n",
    "            padding_size=padding * scale,\n",
    "        )\n",
    "        sr_image = (sr_image * 255).astype(np.uint8)\n",
    "        sr_image = unpad_image(sr_image, pad_size * scale)\n",
    "        sr_image = Image.fromarray(sr_image)\n",
    "        return sr_image\n",
    "\n",
    "\n",
    "def main():\n",
    "    global IMAGE, SCALE, FILE\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if HF_MODELS[SCALE][\"model\"] is None:\n",
    "        HF_MODELS[SCALE][\"model\"] = RealESRGAN(SCALE, device)\n",
    "        HF_MODELS[SCALE][\"model\"].load_weights()\n",
    "\n",
    "    if os.path.exists(IMAGE):\n",
    "        image = Image.open(IMAGE).convert(\"RGB\")\n",
    "    else:\n",
    "        try:\n",
    "            image = urlopen(IMAGE)\n",
    "            image = Image.open(image).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to open {image}: {e}\")\n",
    "            return\n",
    "\n",
    "    model = HF_MODELS[SCALE][\"model\"]\n",
    "    sr_image = model.predict(image)\n",
    "    sr_image.save(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "IMAGE = \"https://raw.githubusercontent.com/ai-forever/Real-ESRGAN/refs/heads/main/inputs/lr_image.png\"\n",
    "FILE = \"sr_image_8x.png\"\n",
    "SCALE = 8\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
